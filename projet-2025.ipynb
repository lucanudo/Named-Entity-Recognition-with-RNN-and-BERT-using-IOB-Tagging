{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b4b4977",
   "metadata": {},
   "source": [
    "# Building models for named entity recognition\n",
    "\n",
    "The project consists in building two named entity recognition (NER) systems. The systems will make use of the IOB tagging scheme to detect entities of type PER, ORG, LOC and MISC. The tagging scheme thus includes the following tags, assuming one tag per token:\n",
    "\n",
    "- B-PER and I-PER: token corresponds to the start, resp. the inside, of a person's entity\n",
    "- B-LOC and I-LOC: token corresponds to the start, resp. the inside, of a location entity\n",
    "- B-ORG and I-ORG: token corresponds to the start, resp. the inside, of an organization entity\n",
    "- B-MISC and I-MISC: token corresponds to the start, resp. the inside, of any other named entity\n",
    "- O: token corresponds to no entity\n",
    "\n",
    "## Dataset\n",
    "\n",
    "You are provided with training, validation and test data derived from the CONLL 03 dataset. The dataset has been marginally cleaned and reformatted for facilitated use. You can directly load the three folds from the json file provided:\n",
    "\n",
    "```python\n",
    "with open('conll03-iob-pos.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "```\n",
    "For each fold, the dataset consists of a list of dictionaries, one per sample, with the two fields 'tokens' and 'labels', e.g.\n",
    "\n",
    "{'tokens': ['EU', 'rejects', 'German', 'call', 'to', 'boycott', 'British', 'lamb', '.'], 'tags': ['B-ORG', 'O', 'B-MISC', 'O', 'O', 'O', 'B-MISC', 'O', 'O']}\n",
    "\n",
    "## TODO\n",
    "\n",
    "Building on the notebooks we've seen during the lectures and on the tipcs below, you task is to build two tagging models:\n",
    "1. a RNN-based model: an embedding layer, a LSTM layer, a feed-forward layer\n",
    "2. a fine-tuned BERT tagger: a BERT (pre-trained) layer, a feed-forward layer\n",
    "The final feed-forward layer procudes a probability distribution over the set possible tags for each input token.\n",
    "\n",
    "For both, we will use BERT's tokenizer, which is a sub-word tokenizer. The advantage of this tokenizer is that the vocabulary is finite (no out-of-vocabulary tokens): you can get the vocabulary size from tokenizer.vocab_size and you don't have to bother with defining your vocabulary and mapping unkown tokens to some special token. The disadvantage of sub-word tokenization is that we will have to relabel the input sequences, which are labeled on a word basis rather than on a sub-word basis. To make things easier, we provide a function that aligns and encode the labels. Note that special tokens will arbitrarily get the tag -100 which is a default value to indicate Torch's loss functions that gradient should not be propagated from there (in other words, ignore thos tokens in training).\n",
    "\n",
    "Another advantage of using the same tokenizer is that you will have to prepare your dataset and the corresponding loaders only once for the two models. \n",
    "\n",
    "Here are the steps you'll have to go through:\n",
    "\n",
    "1. Define a Dataset class that will hold for each sample the list of encoded tokens and the corresponding list of encoded tags. You will then encode the three folds as a Dataset and define the corresponding DataLoader instances. \n",
    "\n",
    "2. Define your LSTM model class and train it. You can get inspired by the RNN language model notebook.\n",
    "\n",
    "3. Define your BERT model class and train it. You can adapt the LLM finetuning notebook, changing the classification head to operate on each token (as for the LSTM) rather than on the embedding of the [CLS] token. \n",
    "\n",
    "4. Evaluate both and compare. Token tag accuracy is one measure (used for instance to measure the convergence of training) but it's not the ultimate one as the final task is not to tag tokens but to detect entities. You should thus also report in the final evaluation the entitu recognition rate.\n",
    "\n",
    "One last thing to think about: computation of the accuracy for validation and testing must be adapted in two ways compared to what we've seen in the previous notebooks. First, each prediction is a sequence of tags and not a single tag. Second, tags corresponding to the special tokens (indicated as -100 in the reference) must not be accounted for when computing the accuracy (maybe pytorch does that for you but you have to make sure it does). \n",
    "\n",
    "**Good luck no your mission!**\n",
    "\n",
    "## REPORT\n",
    "\n",
    "The report will be a commented notebook. This is not a python programing project but a NLP project. I'm thus expecting you to comment on your model definition choices, to analyze the results and errors, to provide hints at how things could be improved. If you did trial and error cells, please clean up a bit to facilitate reading, leaving only the final version in the report notebook.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff19c47",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.13.7' requires the ipykernel package.\n",
      "\u001b[1;31m<a href='command:jupyter.createPythonEnvAndSelectController'>Create a Python Environment</a> with the required packages.\n",
      "\u001b[1;31mOr install 'ipykernel' using the command: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import gzip\n",
    "\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8abc96c6",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.13.7' requires the ipykernel package.\n",
      "\u001b[1;31m<a href='command:jupyter.createPythonEnvAndSelectController'>Create a Python Environment</a> with the required packages.\n",
      "\u001b[1;31mOr install 'ipykernel' using the command: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import gzip\n",
    "\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b24dbe85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O', 'B-LOC', 'I-LOC', 'B-ORG', 'I-ORG', 'B-PER', 'I-PER', 'B-MISC', 'I-MISC']\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# tag to id mapping and vice versa\n",
    "# \n",
    "# for tokens that does not have a tag, we will use -100 as the corresponding tag ID\n",
    "#\n",
    "\n",
    "tag2id = {\n",
    "    'O': 0, \n",
    "    'B-LOC': 1, 'I-LOC': 2,\n",
    "    'B-ORG': 3, 'I-ORG': 4,\n",
    "    'B-PER': 5, 'I-PER': 6, \n",
    "    'B-MISC': 7, 'I-MISC': 8\n",
    "}\n",
    "\n",
    "id2tag = list(tag2id.keys())\n",
    "\n",
    "print(id2tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4acd83e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 14041\n",
      "valid 3250\n",
      "test 3453\n",
      "{'tokens': ['EU', 'rejects', 'German', 'call', 'to', 'boycott', 'British', 'lamb', '.'], 'tags': ['B-ORG', 'O', 'B-MISC', 'O', 'O', 'O', 'B-MISC', 'O', 'O']}\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# load data from json file\n",
    "#\n",
    "\n",
    "with gzip.open('conll03-iob-pos.json.gz', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "for fold in ('train', 'valid', 'test'):\n",
    "    print(fold, len(data[fold]))\n",
    "\n",
    "print(data['train'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a9ca5d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DistilBertTokenizerFast(name_or_path='distilbert-base-cased', vocab_size=28996, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True)\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# load BERT's tokenizer -- this\n",
    "#\n",
    "\n",
    "checkpoint = 'distilbert-base-cased'\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "print(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4878054",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['EU', 'rejects', 'German', 'call', 'to', 'boycott', 'British', 'lamb', '.']\n",
      "['[CLS]', 'EU', 'rejects', 'German', 'call', 'to', 'boycott', 'British', 'la', '##mb', '.', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "[None, 0, 1, 2, 3, 4, 5, 6, 7, 7, 8, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None]\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Here's an example showing how to tokenize texts and create the corresponding aligned and encoded labels\n",
    "#\n",
    "# Note that the tokenizer enables to retrieve the index of the corresponding wordform for each (sub-word) token\n",
    "# through the inputs.word_ids(batch_index=i) function (to retrieve input word indices for each token in \n",
    "# inputs['input_ids'][i]). Special tokens ([CLS], [SEP], [PAD]) are mapped to None. We will make use of this\n",
    "# mapping to create token-level labels adapted to sub-word tokenization. See next cell.\n",
    "#\n",
    "\n",
    "train_texts = [x['tokens'] for x in data['train']]\n",
    "train_labels = [x['tags'] for x in data['train']]\n",
    "\n",
    "inputs = tokenizer(train_texts, is_split_into_words=True, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "print(train_texts[0])\n",
    "print(tokenizer.convert_ids_to_tokens(inputs['input_ids'][0]))\n",
    "print(inputs.word_ids(batch_index=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "47e0d084",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Spanish', 'Farm', 'Minister', 'Loyola', 'de', 'Palacio', 'had', 'earlier', 'accused', 'Fischler', 'at', 'an', 'EU', 'farm', 'ministers', \"'\", 'meeting', 'of', 'causing', 'unjustified', 'alarm', 'through', '\"', 'dangerous', 'generalisation', '.', '\"'] ['B-MISC', 'O', 'O', 'B-PER', 'I-PER', 'I-PER', 'O', 'O', 'O', 'B-PER', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "[CLS]  --  NONE\n",
      "Spanish  --  B-MISC\n",
      "Farm  --  O\n",
      "Minister  --  O\n",
      "Loyola  --  B-PER\n",
      "de  --  I-PER\n",
      "Pa  --  I-PER\n",
      "##la  --  I-PER\n",
      "##cio  --  I-PER\n",
      "had  --  O\n",
      "earlier  --  O\n",
      "accused  --  O\n",
      "Fi  --  B-PER\n",
      "##sch  --  I-PER\n",
      "##ler  --  I-PER\n",
      "at  --  O\n",
      "an  --  O\n",
      "EU  --  B-ORG\n",
      "farm  --  O\n",
      "ministers  --  O\n",
      "'  --  O\n",
      "meeting  --  O\n",
      "of  --  O\n",
      "causing  --  O\n",
      "un  --  O\n",
      "##ju  --  O\n",
      "##st  --  O\n",
      "##ified  --  O\n",
      "alarm  --  O\n",
      "through  --  O\n",
      "\"  --  O\n",
      "dangerous  --  O\n",
      "general  --  O\n",
      "##isation  --  O\n",
      ".  --  O\n",
      "\"  --  O\n",
      "[SEP]  --  NONE\n"
     ]
    }
   ],
   "source": [
    "def align_and_encode_labels(_token_ids, _word_ids, _labels):\n",
    "    '''\n",
    "    Align word-level labels to sub-word tokens for an entry\n",
    "    '''\n",
    "    \n",
    "    global tag2id\n",
    "    \n",
    "    ignore_id = -100\n",
    "    \n",
    "    buf = [ignore_id] # ignore tag for token [CLS]\n",
    "    \n",
    "    prev_token_word = -1\n",
    "    which_type = 0\n",
    "    \n",
    "    # print(len(_token_ids), tokenizer.convert_ids_to_tokens(_token_ids))\n",
    "    # print(_word_ids)\n",
    "    # print(_labels) \n",
    "    \n",
    "    for i in range(1, len(_token_ids)):\n",
    "        word_id = _word_ids[i]\n",
    "        \n",
    "        if word_id == None:\n",
    "            # token does not belong to any input word ([CLS], [SEP] or [PAD]) -- ignore\n",
    "            buf.append(ignore_id)\n",
    "            \n",
    "        else:\n",
    "            tag_id = tag2id[_labels[word_id]]\n",
    "\n",
    "            if word_id == prev_token_word: \n",
    "            # sub-word token of the previous word: need to do something\n",
    "            #   word has an O tag: just use a O tag\n",
    "            #   word has an I-X tag: just use the I-X tag\n",
    "            #   word has a B-X tag: replace by corresponding I-X tag\n",
    "                        \n",
    "                buf.append(tag_id + 1 if tag_id in (1, 3, 5, 7) else tag_id)\n",
    "        \n",
    "            else:\n",
    "                # token starting a new word --> keep tag unchanged\n",
    "                prev_token_word = word_id\n",
    "                buf.append(tag_id)\n",
    "    \n",
    "    return buf\n",
    "\n",
    "#\n",
    "# The following illustrate how we can get aligned and encoded labels for sample i in the training set.\n",
    "#\n",
    "\n",
    "i = 10\n",
    "\n",
    "print(train_texts[i], train_labels[i])\n",
    "\n",
    "new_labels = align_and_encode_labels(inputs['input_ids'][i], inputs.word_ids(batch_index=i), train_labels[i])\n",
    "\n",
    "tokens = tokenizer.convert_ids_to_tokens(inputs['input_ids'][i])\n",
    "\n",
    "for j in range(len(tokens)):\n",
    "    if tokens[j] != '[PAD]':\n",
    "        print(tokens[j], ' -- ', id2tag[new_labels[j]] if new_labels[j] >= 0 else 'NONE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65cfe4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now it's up to you to pursue this notebook, define your datasets, models and evaluate."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
